{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cb51d4",
   "metadata": {},
   "source": [
    "# TwelveLabs / OpenSearch Demonstration\n",
    "\n",
    "Code for the Medium blog post, [Multi-Vector Semantic Search: Advanced Video Search with TwelveLabs and Amazon OpenSearch](https://garystafford.medium.com/multi-vector-semantic-search-advanced-video-search-with-twelve-labs-and-amazon-opensearch-7b81ba52c373). How TwelveLabs AI Models and Amazon OpenSearch Serverless enable multi-vector semantic and hybrid search for video content.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "See README file for prerequisites.\n",
    "\n",
    "Videos must meet the TwelveLabs [requirements](https://docs.twelvelabs.io/docs/get-started/quickstart/create-embeddings#prerequisites):\n",
    "\n",
    "- Video resolution: Must be at least 360x360 and must not exceed 3840x2160.\n",
    "- Aspect ratio: Must be one of 1:1, 4:3, 4:5, 5:4, 16:9, 9:16, or 17:9.\n",
    "- Video and audio formats: Your video files must be encoded in the video and audio formats listed on the FFmpeg Formats Documentation page.\n",
    "- Duration: Must be between 4 seconds and 2 hours (7,200s).\n",
    "- File size: Must not exceed 2 GB.\n",
    "\n",
    "**Workflow Diagram**\n",
    "\n",
    "![Architecture](./twelve_labs_bedrock.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650d3ea",
   "metadata": {},
   "source": [
    "## Install Required Python Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pip -Uq\n",
    "%pip install python-dotenv twelvelabs boto3 opensearch-py -Uq\n",
    "%pip install matplotlib Pillow scikit-learn plotly nbformat pandas -Uq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e8f20",
   "metadata": {},
   "source": [
    "### Restart Kernel\n",
    "\n",
    "If first time installing the packages, restart your Jupyter Notebook's kernel before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0608c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the Twelve Labs package is installed\n",
    "%pip show twelvelabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec95d4",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "There are several ways to load your sensitive environment variables. The package, `python-dotenv`, reads key-value pairs from a plain text `.env` file and can set them as environment variables. We are using the `.env` file to store our sensitive variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads variables from .env file\n",
    "\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "TL_API_KEY = os.getenv(\"TL_API_KEY\")\n",
    "OPENSEARCH_ENDPOINT = os.getenv(\"OPENSEARCH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df2a0f",
   "metadata": {},
   "source": [
    "### Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the TwelveLabs and OpenSearch index names to the same value\n",
    "INDEX_NAME = \"commercials-index\"\n",
    "\n",
    "# Set the local directories for videos, intermediate files, and OpenSearch documents\n",
    "VIDEO_DIRECTORY = \"videos/commercials\"\n",
    "OUTPUT_DIRECTORY = \"output/commercials\"\n",
    "DOCUMENT_DIRECTORY = \"documents/commercials\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ae3bb",
   "metadata": {},
   "source": [
    "## Create TwelveLabs Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bdd9d",
   "metadata": {},
   "source": [
    "### TwelveLabs Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models import Video\n",
    "from twelvelabs.exceptions import NotFoundError\n",
    "\n",
    "tl_client = TwelveLabs(api_key=TL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028aa44",
   "metadata": {},
   "source": [
    "### Create TwelveLabs Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name: str) -> str:\n",
    "    \"\"\"Create a new index for embeddings if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        index_name (str): The name of the index to create.\n",
    "\n",
    "    Returns:\n",
    "        str: The ID of the created index.\n",
    "    \"\"\"\n",
    "    # Check if the index already exists\n",
    "    index_list = tl_client.index.list(\n",
    "        name=index_name,\n",
    "        sort_option=\"asc\",\n",
    "        page_limit=1,\n",
    "    )\n",
    "\n",
    "    # If the index exists, return its ID\n",
    "    if index_list:\n",
    "        for index in index_list:\n",
    "            print(f\"Index '{index.name}' already exists.\")\n",
    "            return index.id\n",
    "\n",
    "    # If the index does not exist, create a new one\n",
    "    print(f\"Creating index '{index_name}'...\")\n",
    "    models = [\n",
    "        {\"name\": \"marengo2.7\", \"options\": [\"visual\", \"audio\"]},\n",
    "        {\"name\": \"pegasus1.2\", \"options\": [\"visual\", \"audio\"]},\n",
    "    ]\n",
    "\n",
    "    created_index = tl_client.index.create(\n",
    "        name=index_name, models=models, addons=[\"thumbnail\"]\n",
    "    )\n",
    "\n",
    "    return created_index.id\n",
    "\n",
    "\n",
    "tl_index_id = create_index(INDEX_NAME)\n",
    "print(f\"Index ID: {tl_index_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda97ca",
   "metadata": {},
   "source": [
    "## Upload Videos to Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_video(tl_index_id: str, video_path: str) -> None:\n",
    "    \"\"\"Upload a video to the TwelveLabs index.\n",
    "\n",
    "    Args:\n",
    "        tl_index_id (str): The ID of the TwelveLabs index.\n",
    "        video_path (str): The path to the video file to upload.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        task = tl_client.task.create(index_id=tl_index_id, file=video_path)\n",
    "        print(f\"Task id={task.id}\")\n",
    "        print(f\"Video '{video_path}' uploaded successfully!\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Failed to upload video '{video_path}': {ex}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(VIDEO_DIRECTORY):\n",
    "    print(f\"Video directory '{VIDEO_DIRECTORY}' does not exist, skipping upload.\")\n",
    "else:\n",
    "    for video in os.listdir(VIDEO_DIRECTORY):\n",
    "        if video.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(VIDEO_DIRECTORY, video)\n",
    "            upload_video(tl_index_id, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9c48b",
   "metadata": {},
   "source": [
    "## Retrieve Embeddings and Analyses from TwelveLabs Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828026a",
   "metadata": {},
   "source": [
    "### Retrieve List of Videos IDs from Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_ids_from_index(tl_index_id: str, page_limit: int = 50) -> list:\n",
    "    \"\"\"Retrieve video IDs from the specified index.\n",
    "\n",
    "    Args:\n",
    "        tl_index_id (str): The ID of the index to query.\n",
    "        page_limit (int): The maximum number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of video IDs retrieved from the index.\n",
    "    \"\"\"\n",
    "    videos = tl_client.index.video.list(\n",
    "        index_id=tl_index_id,\n",
    "        page_limit=page_limit,\n",
    "    )\n",
    "    if not videos:\n",
    "        raise NotFoundError(f\"No videos found in index {tl_index_id}\")\n",
    "\n",
    "    video_ids = list(set(video.id for video in videos))\n",
    "    print(f\"Total count of videos in index {tl_index_id}: {len(video_ids)}\")\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0c737",
   "metadata": {},
   "source": [
    "### Bulk Retrieve Embeddings from Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6850454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_to_json(video: Video, output_path: str) -> None:\n",
    "    \"\"\"Save the embedding task details to a JSON file if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        video (Video): The video object containing embedding details.\n",
    "        output_path (str): The path where the JSON file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Serialize the video object to a dictionary\n",
    "    video_data = video.model_dump_json()\n",
    "    video_data = json.loads(video_data)\n",
    "    video_data[\"video_id\"] = video.id\n",
    "\n",
    "    # Determine the filename using the input filename from the task metadata\n",
    "    input_filename = video_data[\"video_id\"]\n",
    "    output_filename = f\"{output_path}/{input_filename}_embeddings.json\"\n",
    "    if os.path.exists(output_filename):\n",
    "        print(f\"Embeddings already exist for video ID {video.id}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    print(f\"Saving embeddings for video ID {video.id} to {output_filename}\")\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open(output_filename, \"w\") as json_file:\n",
    "        json.dump(video_data, json_file, indent=4)\n",
    "    print(f\"Embeddings saved to {output_filename}\")\n",
    "\n",
    "\n",
    "# Retrieve the video IDs from the index\n",
    "video_ids = get_video_ids_from_index(tl_index_id)\n",
    "\n",
    "# Retrieve the video embeddings from the index and save to JSON\n",
    "if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "    print(f\"Output directory '{OUTPUT_DIRECTORY}' does not exist, skipping retrieval.\")\n",
    "else:\n",
    "    for video_id in video_ids:\n",
    "        print(f\"Processing video ID: {video_id}\")\n",
    "        video = tl_client.index.video.retrieve(\n",
    "            index_id=tl_index_id, id=video_id, embedding_option=[\"visual-text\", \"audio\"]\n",
    "        )\n",
    "        save_embeddings_to_json(video, OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ee245",
   "metadata": {},
   "source": [
    "### Bulk Create Analyses from Videos in Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_video(tl_index_id: str, video_id: str, output_path: str) -> None:\n",
    "    \"\"\"Summarize a video and save the analysis to a JSON file if it doesn't already exist.\n",
    "\n",
    "    Args:\n",
    "        tl_index_id (str): The ID of the index where the video is stored.\n",
    "        video_id (str): The ID of the video to summarize.\n",
    "        output_path (str): The path where the JSON file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path, exist_ok=False)\n",
    "\n",
    "    # Check if the analysis already exists\n",
    "    filename = f\"{output_path}/{video_id}_analysis.json\"\n",
    "    print(video_id)\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Analysis already exists for video ID {video_id}. Skipping...\")\n",
    "        return\n",
    "    print(f\"Analyzing video ID: {video_id}\")\n",
    "\n",
    "    # Get the video summary\n",
    "    res_summary = tl_client.summarize(\n",
    "        video_id=video_id,\n",
    "        prompt=\"Summarize the video in a concise manner.\",\n",
    "        temperature=0.4,\n",
    "        type=\"summary\",\n",
    "    )\n",
    "\n",
    "    # Get the chapters of the video\n",
    "    res_chapters = tl_client.summarize(\n",
    "        video_id=video_id,\n",
    "        prompt=\"List the chapters of the video.\",\n",
    "        temperature=0.4,\n",
    "        type=\"chapter\",\n",
    "    )\n",
    "\n",
    "    # Get the highlights of the video\n",
    "    res_highlights = tl_client.summarize(\n",
    "        video_id=video_id,\n",
    "        prompt=\"List the highlights of the video.\",\n",
    "        temperature=0.4,\n",
    "        type=\"highlight\",\n",
    "    )\n",
    "\n",
    "    # Get open-ended text analysis of the video\n",
    "    res_analyze = tl_client.analyze(\n",
    "        video_id=video_id,\n",
    "        prompt=\"Describe what is happening in the video.\",\n",
    "        temperature=0.4,\n",
    "    )\n",
    "\n",
    "    # Get the gist of the video\n",
    "    res_gist = tl_client.gist(video_id=video_id, types=[\"title\", \"topic\", \"hashtag\"])\n",
    "\n",
    "    # Combined responses\n",
    "    analyses = {}\n",
    "\n",
    "    analyses.update(\n",
    "        {\n",
    "            \"gist\": res_gist.model_dump(),\n",
    "            \"video_id\": video_id,\n",
    "            \"index_id\": tl_index_id,\n",
    "            \"summary\": res_summary.summary,\n",
    "            \"analysis\": res_analyze.data,\n",
    "            \"chapters\": res_chapters.chapters.model_dump(),\n",
    "            \"highlights\": res_highlights.highlights.model_dump(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Save to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(analyses))\n",
    "\n",
    "\n",
    "# Retrieve the video IDs from the index\n",
    "video_ids = get_video_ids_from_index(tl_index_id)\n",
    "\n",
    "# Retrieve the video analysis from the index and save to JSON\n",
    "if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "    print(f\"Output directory '{OUTPUT_DIRECTORY}' does not exist, skipping analysis.\")\n",
    "else:\n",
    "    for video_id in video_ids:\n",
    "        print(f\"Processing video ID: {video_id}\")\n",
    "        summarize_video(tl_index_id, video_id, OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b3c35",
   "metadata": {},
   "source": [
    "### Merge Embeddings and Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_ids(output_path: str) -> list:\n",
    "    \"\"\"Extract video IDs from analysis filenames in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        output_path (str): Directory containing the analysis JSON files\n",
    "\n",
    "    Returns:\n",
    "        list: List of extracted video IDs\n",
    "    \"\"\"\n",
    "    video_ids = []\n",
    "\n",
    "    for filename in os.listdir(output_path):\n",
    "        # Check if it's an analysis file\n",
    "        if filename.endswith(\"_analysis.json\"):\n",
    "            # Extract the ID part from the filename\n",
    "            # The ID is everything before \"_analysis.json\"\n",
    "            video_id = filename.split(\"_analysis.json\")[0]\n",
    "            video_ids.append(video_id)\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "    print(f\"Output directory '{OUTPUT_DIRECTORY}' does not exist, skipping extraction.\")\n",
    "else:\n",
    "    video_ids = extract_video_ids(OUTPUT_DIRECTORY)\n",
    "    print(f\"Found {len(video_ids)} video IDs: {video_ids[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a658e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_segments_to_documents(\n",
    "    output_path: str, document_path: str, video_ids: list\n",
    ") -> None:\n",
    "    \"\"\"Combine embeddings and analyses into single documents and save them to a local directory.\n",
    "\n",
    "    Args:\n",
    "        output_path (str): Directory containing the analysis and embeddings JSON files\n",
    "        document_path (str): Directory to save the combined document files\n",
    "        video_ids (list): List of video IDs to process\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for video_id in video_ids:\n",
    "        filename = f\"{document_path}/{video_id}_document.json\"\n",
    "        # Check if the document already exists\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Document already exists for video ID {video_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing video ID: {video_id}\")\n",
    "        # Open corresponding analyses and embeddings documents and combined\n",
    "        with open(f\"{output_path}/{video_id}_embeddings.json\", \"r\") as f:\n",
    "            embeddings = json.load(f)\n",
    "\n",
    "        with open(f\"{output_path}/{video_id}_analysis.json\", \"r\") as f:\n",
    "            analyses = json.load(f)\n",
    "\n",
    "        # Combine the two documents\n",
    "        document = {}\n",
    "        document.update(analyses)\n",
    "        document.update(embeddings)\n",
    "\n",
    "        # Remove unneeded keys\n",
    "        document[\"gist\"].pop(\"id\", None)\n",
    "        document[\"gist\"].pop(\"usage\", None)\n",
    "\n",
    "        # Segments of video\n",
    "        segments = document[\"embedding\"][\"video_embedding\"][\"segments\"]\n",
    "\n",
    "        # Write documents to local directory for each segment\n",
    "        document.pop(\"embedding\", None)\n",
    "        document[\"segments\"] = segments\n",
    "        for segment in document[\"segments\"]:\n",
    "            segment[\"segment_embedding\"] = segment[\"embeddings_float\"].copy()\n",
    "            segment.pop(\"embeddings_float\", None)\n",
    "\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(json.dumps(document, indent=4))\n",
    "\n",
    "\n",
    "if not os.path.exists(DOCUMENT_DIRECTORY):\n",
    "    print(\n",
    "        f\"Document directory '{DOCUMENT_DIRECTORY}' does not exist, skipping document creation.\"\n",
    "    )\n",
    "elif not os.path.exists(OUTPUT_DIRECTORY):\n",
    "    print(\n",
    "        f\"Output directory '{OUTPUT_DIRECTORY}' does not exist, skipping document creation.\"\n",
    "    )\n",
    "else:\n",
    "    combine_segments_to_documents(OUTPUT_DIRECTORY, DOCUMENT_DIRECTORY, video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4b1de",
   "metadata": {},
   "source": [
    "## OpenSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b5d57",
   "metadata": {},
   "source": [
    "### Load Required Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from opensearchpy import (\n",
    "    AWSV4SignerAuth,\n",
    "    NotFoundError,\n",
    "    OpenSearch,\n",
    "    RequestsHttpConnection,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68da6c0",
   "metadata": {},
   "source": [
    "### Option #1: Amazon OpenSearch Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenSearch client for Amazon OpenSearch Serverless\n",
    "# https://opensearch.org/docs/latest/clients/python-low-level/#connecting-to-amazon-opensearch-serverless\n",
    "\n",
    "service = \"aoss\"\n",
    "credentials = boto3.Session(\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=AWS_REGION,\n",
    ").get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, AWS_REGION, service)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_ENDPOINT, \"port\": 443}],\n",
    "    http_auth=auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    ")\n",
    "\n",
    "os_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda68058",
   "metadata": {},
   "source": [
    "### Option #2: OpenSearch Client Running in Docker\n",
    "\n",
    "Recommended for local development and debugging purposes only as an alternative to Amazon OpenSearch Serverless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress security warnings related to unverified HTTPS requests and SSL connections\n",
    "warnings.filterwarnings(\"ignore\", message=\"Unverified HTTPS request\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\"Connecting to https://localhost:9200 using SSL\"\n",
    ")\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_ENDPOINT, \"port\": 9200}],\n",
    "    http_auth=(\"admin\", \"OpenSearch123\"),\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    ")\n",
    "\n",
    "os_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041a8e4",
   "metadata": {},
   "source": [
    "### Create New OpenSearch Vector Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1186c",
   "metadata": {},
   "source": [
    "#### Optionally: Delete Existing Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62faa230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index(os_client, os_index: str) -> None:\n",
    "    \"\"\"Delete an index in OpenSearch.\n",
    "\n",
    "    Args:\n",
    "        os_client (OpenSearch): The OpenSearch client instance.\n",
    "        os_index (str): The name of the index to delete.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os_client.indices.exists(index=os_index):\n",
    "        print(f\"Index '{os_index}' does not exist.\")\n",
    "    else:\n",
    "        os_client.indices.delete(index=os_index)\n",
    "        print(f\"Index '{os_index}' deleted successfully.\")\n",
    "\n",
    "\n",
    "# Delete the OpenSearch index for video embeddings\n",
    "delete_index(os_client, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9841fc9",
   "metadata": {},
   "source": [
    "#### Create New Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/\n",
    "\n",
    "\n",
    "def create_index(os_client, os_index: str) -> None:\n",
    "    \"\"\"Create an index in OpenSearch with specified settings and mappings.\n",
    "\n",
    "    Args:\n",
    "        os_client (OpenSearch): The OpenSearch client instance.\n",
    "        os_index (str): The name of the index to create.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if os_client.indices.exists(index=os_index):\n",
    "        print(f\"Index '{os_index}' already exists.\")\n",
    "        return\n",
    "\n",
    "    index_body = {\n",
    "        \"settings\": {\n",
    "            \"index\": {\n",
    "                \"knn\": True,\n",
    "                \"number_of_shards\": 2,\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"segments\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"segment_embedding\": {\n",
    "                            \"type\": \"knn_vector\",\n",
    "                            \"dimension\": 1024,\n",
    "                            \"method\": {\n",
    "                                \"engine\": \"faiss\",\n",
    "                                \"name\": \"hnsw\",\n",
    "                                \"space_type\": \"cosinesimil\",  # Use l2 for Amazon OpenSearch Serverless\n",
    "                            },\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Check if the index already exists\n",
    "    if os_client.indices.exists(index=os_index):\n",
    "        print(f\"Index '{os_index}' already exists.\")\n",
    "    else:\n",
    "        os_client.indices.create(index=os_index, body=index_body)\n",
    "        print(f\"Index '{os_index}' created successfully.\")\n",
    "\n",
    "\n",
    "# Create the OpenSearch index for video embeddings\n",
    "create_index(os_client, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b360e",
   "metadata": {},
   "source": [
    "#### Retrieve Information About OpenSearch Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = os_client.indices.get(index=INDEX_NAME)\n",
    "    print(json.dumps(response, indent=4))\n",
    "except NotFoundError as ex:\n",
    "    print(f\"Index not found: {ex}\")\n",
    "except Exception as ex:\n",
    "    print(ex.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad06a2f",
   "metadata": {},
   "source": [
    "### Bulk Index OpenSearch Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10219d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_index_documents(os_index: str, document_path: str) -> None:\n",
    "    \"\"\"Load documents from JSON files in the specified directory and index them in OpenSearch.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The name of the OpenSearch index to create or use.\n",
    "        document_path (str): Directory containing the document JSON files\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    payload = \"\"\n",
    "    put_command = f'{{ \"create\": {{ \"_index\": \"{os_index}\" }} }}\\n'\n",
    "\n",
    "    for file in os.listdir(document_path):\n",
    "        if file.endswith(\"_document.json\"):\n",
    "            with open(os.path.join(document_path, file), \"r\") as f:\n",
    "                tmp = json.load(f)\n",
    "                payload += f\"{put_command}{json.dumps(tmp)}\\n\"\n",
    "    try:\n",
    "        response = os_client.bulk(\n",
    "            index=os_index,\n",
    "            body=payload,\n",
    "        )\n",
    "        print(json.dumps(response, indent=4))\n",
    "        row_count = int(len(payload.splitlines()) / 2)\n",
    "        return row_count\n",
    "    except Exception as ex:\n",
    "        print(f\"Error indexing documents: {ex}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "if not os.path.exists(DOCUMENT_DIRECTORY):\n",
    "    print(\n",
    "        f\"Document directory '{DOCUMENT_DIRECTORY}' does not exist, skipping indexing.\"\n",
    "    )\n",
    "else:\n",
    "    row_count = load_and_index_documents(INDEX_NAME, DOCUMENT_DIRECTORY)\n",
    "    print(f\"Total rows to index: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# Wait for Amazon OpenSearch Serverless indexing to complete and refresh (~60s)\n",
    "response = os_client.count(index=INDEX_NAME)\n",
    "while response[\"count\"] != row_count:\n",
    "    response = os_client.count(index=INDEX_NAME)\n",
    "    print(f\"Current indexed documents: {response['count']}\")\n",
    "    sleep(10)\n",
    "print(f\"Indexing completed. Total indexed documents: {response['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80085f1c",
   "metadata": {},
   "source": [
    "## Query the Amazon OpenSearch Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee0925",
   "metadata": {},
   "source": [
    "### Convert User Text Query to Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding_from_query(query: str) -> list:\n",
    "    \"\"\"Convert a text query to an embedding using TwelveLabs.\n",
    "\n",
    "    Args:\n",
    "        query (str): The text query to convert.\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding vector.\n",
    "    \"\"\"\n",
    "    response = tl_client.embed.create(\n",
    "        model_name=\"Marengo-retrieval-2.7\",\n",
    "        text_truncate=\"start\",\n",
    "        text=query,\n",
    "    )\n",
    "    # print(response)\n",
    "    if (\n",
    "        response.text_embedding is not None\n",
    "        and response.text_embedding.segments is not None\n",
    "    ):\n",
    "        return response.text_embedding.segments[0].embeddings_float\n",
    "    else:\n",
    "        raise ValueError(\"Failed to retrieve embedding from the response.\")\n",
    "\n",
    "\n",
    "query = \"elderly drivers\"  # \"who charges me less but gives me more\"  # \"boom boom boom to the baseline\" # \"switch to a turbo tax live expert\"\n",
    "text_embedding = get_text_embedding_from_query(query)\n",
    "print(f\"Embedding: {text_embedding[:5]}...\")  # Print first 5 elements for brevity\n",
    "\n",
    "# Optionally save the text embedding to a JSON file for later use\n",
    "with open(\"text_embedding.json\", \"w\") as f:\n",
    "    json.dump(text_embedding, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1753c2f",
   "metadata": {},
   "source": [
    "### Convert Sample Image to Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c066aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embedding_from_query(image_file: str) -> list:\n",
    "    \"\"\"Convert an image file to an embedding using TwelveLabs.\n",
    "\n",
    "    Args:\n",
    "        query (str): The text query to convert.\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding vector.\n",
    "    \"\"\"\n",
    "    response = tl_client.embed.create(\n",
    "        model_name=\"Marengo-retrieval-2.7\",\n",
    "        image_file=image_file,\n",
    "    )\n",
    "    print(response)\n",
    "    if (\n",
    "        response.image_embedding is not None\n",
    "        and response.image_embedding.segments is not None\n",
    "    ):\n",
    "        return response.image_embedding.segments[0].embeddings_float\n",
    "    else:\n",
    "        raise ValueError(\"Failed to retrieve embedding from the response.\")\n",
    "\n",
    "\n",
    "image_embedding = get_image_embedding_from_query(\n",
    "    \"sample_images/nike_dream_crazier_clip.png\"\n",
    ")\n",
    "print(f\"Embedding: {image_embedding[:5]}...\")  # Print first 5 elements for brevity\n",
    "\n",
    "# Optionally save the image embedding to a JSON file for later use\n",
    "with open(\"image_embedding.json\", \"w\") as f:\n",
    "    json.dump(image_embedding, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Reload the embeddings from JSON files instead of calling the API repeatedly.\n",
    "# This can be useful for offline use or debugging and testing purposes.\n",
    "\n",
    "text_embedding = json.load(open(\"text_embedding.json\", \"r\"))\n",
    "image_embedding = json.load(open(\"image_embedding.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601932b",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search (Approximate k-NN Search (ANN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d698c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/vector-search-techniques/approximate-knn/#get-started-with-approximate-k-nn\n",
    "\n",
    "\n",
    "def semantic_search(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_1 = semantic_search(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_1[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2598e3",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08bf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/filter-search-knn/efficient-knn-filtering/\n",
    "\n",
    "\n",
    "def semantic_search_with_filter(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with a filter on segment duration.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                            \"filter\": {\n",
    "                                \"bool\": {\n",
    "                                    \"must\": [\n",
    "                                        {\n",
    "                                            \"range\": {\n",
    "                                                \"system_metadata.duration\": {\n",
    "                                                    \"gte\": 20,\n",
    "                                                    \"lte\": 60,\n",
    "                                                }\n",
    "                                            }\n",
    "                                        },\n",
    "                                    ]\n",
    "                                }\n",
    "                            },\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_2 = semantic_search_with_filter(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_2[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb548f93",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with Inner Hits\n",
    "\n",
    "Include information about the matching nested fields in the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee98102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#inner-hits\n",
    "\n",
    "\n",
    "def semantic_search_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"segments.start_offset_sec\",\n",
    "                        \"segments.end_offset_sec\",\n",
    "                        \"segments.embedding_option\",\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_3 = semantic_search_inner_hits(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_3[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"Matching Segment:\")\n",
    "    for segment in hit[\"inner_hits\"][\"segments\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['segments.embedding_option'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['segments.start_offset_sec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['segments.end_offset_sec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dd1e6",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with all Nested Hits\n",
    "\n",
    "To retrieve the scores for all nested field documents within each parent document. By default, only the highest-scoring nested document is considered when you query nested fields.\n",
    "\n",
    "_Note that as of 2025-06-28, although Amazon OpenSearch Serverless claims that it supports version 2.19, the `expand_nested_docs` is not available (error: `Error querying index: RequestError(400, 'x_content_parse_exception', '[1:12885] [knn] unknown field [expand_nested_docs]')`). The below search was performed in OpenSearch using Docker._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82983df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 6,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"segments.start_offset_sec\",\n",
    "                        \"segments.end_offset_sec\",\n",
    "                        \"segments.embedding_option\",\n",
    "                        \"segments.segment_embedding\",\n",
    "                    ],\n",
    "                    \"size\": 3,\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_4 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "for hit in search_results_4[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"Matching Segment(s):\")\n",
    "    for segment in hit[\"inner_hits\"][\"segments\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['segments.embedding_option'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['segments.start_offset_sec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['segments.end_offset_sec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407054ef",
   "metadata": {},
   "source": [
    "### Nested k-NN Semantic Search with all Nested Hits, with Filtering on Nested Fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a62aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 3,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"filter\": {\"term\": {\"segments.embedding_option\": \"audio\"}},\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"segments.start_offset_sec\",\n",
    "                        \"segments.end_offset_sec\",\n",
    "                        \"segments.embedding_option\",\n",
    "                    ],\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 3,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_5 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "for hit in search_results_5[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"Matching Segment(s):\")\n",
    "    for segment in hit[\"inner_hits\"][\"segments\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['segments.embedding_option'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['segments.start_offset_sec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['segments.end_offset_sec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b659",
   "metadata": {},
   "source": [
    "### Radial Search\n",
    "\n",
    "Search all points within a vector space that reside within a specified maximum distance or minimum score threshold from a query point (squared Euclidean distance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/radial-search-knn/\n",
    "\n",
    "\n",
    "def radial_search(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with radial search to find segments within a certain distance.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"max_distance\": 1,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 6,\n",
    "        \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_6 = semantic_search(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_6[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2103e",
   "metadata": {},
   "source": [
    "## Displaying Previews of Search Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e98dd5",
   "metadata": {},
   "source": [
    "### Visual Grid of Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from urllib import request\n",
    "import io\n",
    "\n",
    "\n",
    "def load_image_from_url(url: str) -> Image.Image:\n",
    "    \"\"\"Load an image from a URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the image to load.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: The loaded image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with request.urlopen(url) as response:\n",
    "            image_data = response.read()\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading video thumbnail from URL: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "index = 1\n",
    "rows = 3\n",
    "columns = 3\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "for hit in search_results_1[\"hits\"][\"hits\"]:\n",
    "    fig.set_dpi(300)\n",
    "    fig.add_subplot(rows, columns, index)\n",
    "    image_url = hit[\"_source\"][\"hls\"][\"thumbnail_urls\"][0]\n",
    "    image = load_image_from_url(image_url)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.title(\n",
    "        f'Video: {hit[\"_source\"][\"system_metadata\"][\"filename\"][0:40]}\\nScore: {hit[\"_score\"]}',\n",
    "        fontdict=dict(family=\"Arial\", size=8),\n",
    "        color=\"black\",\n",
    "    )\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250733bf",
   "metadata": {},
   "source": [
    "### 2D/3D Visualizations Using t-SNE\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is a popular technique for reducing high-dimensional data, such as embeddings, to 2 or 3 dimensions for visualization or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4eba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_t_sne(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch including embeddings.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 9,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"segments.start_offset_sec\",\n",
    "                        \"segments.end_offset_sec\",\n",
    "                        \"segments.embedding_option\",\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"size\": 9,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_7 = semantic_search_t_sne(INDEX_NAME, text_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and video names from the search results\n",
    "results = []\n",
    "\n",
    "for hit in search_results_7[\"hits\"][\"hits\"]:\n",
    "    results.append(\n",
    "        [\n",
    "            hit[\"_source\"][\"segments\"][0][\"segment_embedding\"],\n",
    "            hit[\"_source\"][\"system_metadata\"][\"filename\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "results.append([text_embedding, \"User query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e165b",
   "metadata": {},
   "source": [
    "#### 2D Visualization Using t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97164d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Initialize t-SNE (n_components=2 for 2D reduction)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "\n",
    "# Extract embeddings and apply t-SNE\n",
    "embeddings = np.array([res[0] for res in results])\n",
    "embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Combine the reduced embeddings with their corresponding video names\n",
    "vis_dims_2d = list(\n",
    "    map(\n",
    "        lambda x: [x[0][0], x[0][1], x[1]], zip(embeddings, [res[1] for res in results])\n",
    "    )\n",
    ")\n",
    "print(vis_dims_2d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Search results\n",
    "for i, video_name in enumerate(vis_dims_2d[0:-1]):\n",
    "    x = np.array([vis_dims_2d[i][0]])\n",
    "    y = np.array([vis_dims_2d[i][1]])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=15,\n",
    "                colorscale=\"Viridis\",\n",
    "                opacity=1.0,\n",
    "                symbol=\"circle\",\n",
    "            ),\n",
    "            name=vis_dims_2d[i][2][0:25],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # User query\n",
    "    x = np.array([vis_dims_2d[-1][0]])\n",
    "    y = np.array([vis_dims_2d[-1][1]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode=\"text+markers\",\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color=\"black\",\n",
    "            colorscale=\"Viridis\",\n",
    "            opacity=1.0,\n",
    "            symbol=\"square\",\n",
    "        ),\n",
    "        name=vis_dims_2d[-1][2][0:25],\n",
    "        text=vis_dims_2d[-1][2],\n",
    "        textposition=\"bottom center\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=12, color=\"black\", family=\"Arial, sans-serif\"),\n",
    "    title=\"Commercials Search Results using t-SNE\",\n",
    "    margin=dict(l=30, r=30, b=30, t=60, pad=10),\n",
    "    xaxis=dict(title=\"x\"),\n",
    "    yaxis=dict(title=\"y\"),\n",
    "    legend=dict(title=\"   Search Results\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160c095",
   "metadata": {},
   "source": [
    "#### 3D Visualization Using t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Initialize t-SNE (n_components=3 for 3D reduction)\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=5)\n",
    "\n",
    "# Extract embeddings and apply t-SNE\n",
    "embeddings = np.array([res[0] for res in results])\n",
    "embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Combine the reduced embeddings with their corresponding video names\n",
    "vis_dims_3d = list(\n",
    "    map(\n",
    "        lambda x: [x[0][0], x[0][1], x[0][2], x[1]],\n",
    "        zip(embeddings, [res[1] for res in results]),\n",
    "    )\n",
    ")\n",
    "print(vis_dims_3d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95902df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Results\n",
    "for i, video_name in enumerate(vis_dims_3d[0:-1]):\n",
    "    x = np.array([vis_dims_3d[i][0]])\n",
    "    y = np.array([vis_dims_3d[i][1]])\n",
    "    z = np.array([vis_dims_3d[i][2]])\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=7, colorscale=\"Viridis\", opacity=1.0, symbol=\"circle\"),\n",
    "            name=vis_dims_3d[i][3][0:25],\n",
    "            text=vis_dims_3d[i][3][0:25],\n",
    "            textposition=\"top center\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # User query\n",
    "    x = np.array([vis_dims_3d[-1][0]])\n",
    "    y = np.array([vis_dims_3d[-1][1]])\n",
    "    z = np.array([vis_dims_3d[-1][2]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=7, color=\"black\", colorscale=\"Viridis\", opacity=1.0, symbol=\"square\"\n",
    "        ),\n",
    "        name=vis_dims_3d[-1][3],\n",
    "        text=vis_dims_3d[-1][3],\n",
    "        textposition=\"top center\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "x_eye = -1.25\n",
    "y_eye = 1.5\n",
    "z_eye = 0.5\n",
    "\n",
    "fig.update_layout(\n",
    "    # autosize=True,\n",
    "    width=900,\n",
    "    height=600,\n",
    "    font=dict(size=12, color=\"black\", family=\"Arial, sans-serif\"),\n",
    "    title=\"Commercials Search Results using t-SNE\",\n",
    "    margin=dict(l=30, r=30, b=30, t=50, pad=10),\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"z\"),\n",
    "        yaxis=dict(title=\"x\"),\n",
    "        zaxis=dict(title=\"y\"),\n",
    "    ),\n",
    "    scene_camera_eye=dict(x=x_eye, y=y_eye, z=z_eye),\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=True,\n",
    "            y=0.9,\n",
    "            x=0.9,\n",
    "            xanchor=\"left\",\n",
    "            yanchor=\"bottom\",\n",
    "            pad=dict(t=10, r=10),\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"Play\",\n",
    "                    method=\"animate\",\n",
    "                    args=[\n",
    "                        None,\n",
    "                        dict(\n",
    "                            frame=dict(duration=15, redraw=True),\n",
    "                            transition=dict(duration=1),\n",
    "                            fromcurrent=True,\n",
    "                            mode=\"immediate\",\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    legend=dict(\n",
    "        title=\"   Search Results\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def rotate_z(x, y, z, theta):\n",
    "    w = x + 1j * y\n",
    "    return np.real(np.exp(1j * theta) * w), np.imag(np.exp(1j * theta) * w), z\n",
    "\n",
    "\n",
    "frames = []\n",
    "for t in np.arange(0, 10, 0.01):\n",
    "    xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "    frames.append(go.Frame(layout=dict(scene_camera_eye=dict(x=xe, y=ye, z=ze))))\n",
    "fig.frames = frames\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a34ab",
   "metadata": {},
   "source": [
    "### Extracting a List of Segments from Video Search Results\n",
    "\n",
    "Reorder the search results as a list of segments as opposed to a list of videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://docs.opensearch.org/docs/latest/vector-search/specialized-operations/nested-search-knn/#retrieving-all-nested-hits\n",
    "\n",
    "\n",
    "def semantic_search_all_inner_hits(os_index: str, embedding: list) -> dict:\n",
    "    \"\"\"Query the OpenSearch index using a text embedding with inner hits to retrieve all matching nested segments.\n",
    "\n",
    "    Args:\n",
    "        os_index (str): The ID of the Amazon OpenSearch index.\n",
    "        embedding (list): The embedding vector to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The search response from OpenSearch.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"segments\",\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                        \"segments.segment_embedding\": {\n",
    "                            \"vector\": embedding,\n",
    "                            \"k\": 50,\n",
    "                            \"expand_nested_docs\": True,\n",
    "                            \"rescore\": True,\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"_source\": False,\n",
    "                    \"fields\": [\n",
    "                        \"segments.start_offset_sec\",\n",
    "                        \"segments.end_offset_sec\",\n",
    "                        \"segments.embedding_option\",\n",
    "                        \"segments.segment_embedding\",\n",
    "                    ],\n",
    "                    \"size\": 50,\n",
    "                },\n",
    "                \"score_mode\": \"max\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 50,\n",
    "        # \"_source\": {\"excludes\": [\"segments.segment_embedding\"]},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        search_results = os_client.search(body=query, index=os_index)\n",
    "        return search_results\n",
    "    except Exception as ex:\n",
    "        print(f\"Error querying index: {ex}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Query the index with the embedding\n",
    "search_results_8 = semantic_search_all_inner_hits(INDEX_NAME, text_embedding)\n",
    "\n",
    "for hit in search_results_8[\"hits\"][\"hits\"]:\n",
    "    print(f\"Video ID: {hit['_source']['video_id']}\")\n",
    "    print(f\"Title: {hit['_source']['gist']['title']}\")\n",
    "    print(f\"Score: {hit['_score']}\")\n",
    "    print(f\"Duration: {hit['_source']['system_metadata']['duration']:.2f} seconds\")\n",
    "    print(\"Matching Segment(s):\")\n",
    "    for segment in hit[\"inner_hits\"][\"segments\"][\"hits\"][\"hits\"]:\n",
    "        print(f\"  Segment: {segment['_nested']['offset']}\")\n",
    "        print(f\"    Score: {segment['_score']}\")\n",
    "        print(\n",
    "            f\"    Embedding type: {segment['fields']['segments.embedding_option'][0]}\"\n",
    "        )\n",
    "        print(f\"    Start: {segment['fields']['segments.start_offset_sec'][0]} seconds\")\n",
    "        print(f\"    End: {segment['fields']['segments.end_offset_sec'][0]} seconds\")\n",
    "    print(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments_sorted_by_score(results: dict) -> list:\n",
    "    \"\"\"Extract segments from search results and sort them by score.\n",
    "\n",
    "    Args:\n",
    "        results (dict): The search results from the OpenSearch query.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of segments sorted by their score in descending order.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    for hit in results[\"hits\"][\"hits\"]:\n",
    "        for segment in hit[\"inner_hits\"][\"segments\"][\"hits\"][\"hits\"]:\n",
    "            segment_score = {}\n",
    "            segment_score[\"title\"] = hit[\"_source\"][\"gist\"][\"title\"]\n",
    "            segment_score[\"filename\"] = hit[\"_source\"][\"system_metadata\"][\"filename\"]\n",
    "            segment_score[\"offset\"] = segment[\"_nested\"][\"offset\"]\n",
    "            segment_score[\"_score\"] = segment[\"_score\"]\n",
    "            segment_score[\"embedding_option\"] = segment[\"fields\"][\n",
    "                \"segments.embedding_option\"\n",
    "            ][0]\n",
    "            segment_score[\"start_offset_sec\"] = round(\n",
    "                segment[\"fields\"][\"segments.start_offset_sec\"][0], 2\n",
    "            )\n",
    "            segment_score[\"end_offset_sec\"] = round(\n",
    "                segment[\"fields\"][\"segments.end_offset_sec\"][0], 2\n",
    "            )\n",
    "            segment_score[\"embedding\"] = segment[\"fields\"][\"segments.segment_embedding\"]\n",
    "            segments.append(segment_score)\n",
    "\n",
    "    segments = sorted(segments, key=lambda x: x[\"_score\"], reverse=True)\n",
    "    # print(json.dumps(segments[:3], indent=4))\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc6910",
   "metadata": {},
   "source": [
    "#### Display Top Video Segment from Search Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b695412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "video_file = segments[0][\"filename\"]\n",
    "segment_start = segments[0][\"start_offset_sec\"]\n",
    "segment_end = segments[0][\"end_offset_sec\"]\n",
    "\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "    <h2>Segment Details</h2>\n",
    "    <p>Filename: {video_file}</p>\n",
    "    <p>Segment start: {segment_start} seconds</p>\n",
    "    <p>Segment end: {segment_end} seconds</p>\n",
    "    <video width=\"600\" height=\"auto\" controls>\n",
    "        <source src=\"videos//commercials//{video_file}#t={segment_start},{segment_end}\" type=\"video/mp4\">\n",
    "    </video>    \n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c54ca0",
   "metadata": {},
   "source": [
    "#### Display All Segments in 2D Scatter Plot Using PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used to simplify complex datasets by transforming the original variables into a new set of uncorrelated variables called principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "# Extract segments and their embeddings from the search results\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "embeddings = list(map(lambda segment: segment[\"embedding\"], segments))\n",
    "\n",
    "# Reduce the dense vector embedding's dimensions from 1,024 to 2 using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the PCA model to the embeddings and transform them to 2D\n",
    "vis_dims_2d = pca.fit_transform(embeddings)\n",
    "print(f\"Reduced dimensions shape (2d): {vis_dims_2d.shape}\")\n",
    "\n",
    "# Create a new list of segments with the 2D embeddings\n",
    "segments = list(\n",
    "    map(\n",
    "        lambda segment, vis_dim: {**segment, \"embedding\": vis_dim},\n",
    "        segments,\n",
    "        vis_dims_2d,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    segments,\n",
    "    x=[segment[\"embedding\"][0] for segment in segments],\n",
    "    y=[segment[\"embedding\"][1] for segment in segments],\n",
    "    color=[segment[\"filename\"] for segment in segments],\n",
    "    hover_name=[segment[\"filename\"] for segment in segments],\n",
    "    hover_data=[\"embedding_option\", \"start_offset_sec\", \"end_offset_sec\", \"offset\"],\n",
    "    title=\"All Commercial Segments using PCA\",\n",
    "    labels={\"x\": \"PCA Dimension 1\", \"y\": \"PCA Dimension 2\"},\n",
    "    width=900,\n",
    "    height=600,\n",
    "    opacity=0.75,\n",
    ")\n",
    "\n",
    "fig.layout.xaxis.scaleanchor = \"y\"\n",
    "fig.layout.yaxis.scaleanchor = \"x\"\n",
    "fig.layout.xaxis.scaleratio = 1\n",
    "fig.layout.yaxis.scaleratio = 1\n",
    "fig.layout.xaxis.dtick = 0.25\n",
    "fig.layout.yaxis.dtick = 0.25\n",
    "fig.layout.legend = dict(\n",
    "    title_text=\"Embedding Type\",\n",
    "    font=dict(size=10, family=\"Arial, sans-serif\"),\n",
    ")\n",
    "fig.layout.title.font = dict(\n",
    "    size=16,\n",
    "    family=\"Arial, sans-serif\",\n",
    ")\n",
    "fig.layout.showlegend = False\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe750cb",
   "metadata": {},
   "source": [
    "#### Display All Segments in 2D Scatter Plot Using t-SNE\n",
    "\n",
    "t-SNE (t-distributed Stochastic Neighbor Embedding) is a popular technique for reducing high-dimensional data, such as embeddings, to 2 or 3 dimensions for visualization or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8eb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Extract segments and their embeddings from the search results\n",
    "segments = extract_segments_sorted_by_score(search_results_8)\n",
    "embeddings = list(map(lambda segment: segment[\"embedding\"], segments))\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# Initialize t-SNE (n_components=2 for 2D reduction)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the embeddings\n",
    "vis_dims_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Find clusters using KMeans\n",
    "kmeans = KMeans(n_clusters=70, random_state=0).fit(vis_dims_2d)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Create a new list of segments with the 2D embeddings\n",
    "segments = list(\n",
    "    map(\n",
    "        lambda segment, vis_dim: {**segment, \"embedding\": vis_dim},\n",
    "        segments,\n",
    "        vis_dims_2d,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    segments,\n",
    "    x=[segment[\"embedding\"][0] for segment in segments],\n",
    "    y=[segment[\"embedding\"][1] for segment in segments],\n",
    "    color=[segment[\"filename\"][0:10] for segment in segments],\n",
    "    hover_name=[segment[\"filename\"] for segment in segments],\n",
    "    hover_data=[\"embedding_option\", \"start_offset_sec\", \"end_offset_sec\", \"offset\"],\n",
    "    title=\"All Commercial Segments using t-SNE\",\n",
    "    labels={\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"},\n",
    "    width=900,\n",
    "    height=600,\n",
    "    opacity=0.75,\n",
    ")\n",
    "\n",
    "fig.layout.xaxis.scaleanchor = \"y\"\n",
    "fig.layout.yaxis.scaleanchor = \"x\"\n",
    "fig.layout.xaxis.scaleratio = 1\n",
    "fig.layout.yaxis.scaleratio = 1\n",
    "fig.layout.xaxis.dtick = 5\n",
    "fig.layout.yaxis.dtick = 5\n",
    "fig.layout.legend = dict(\n",
    "    title_text=\"Commercial\",\n",
    "    font=dict(size=10, family=\"Arial, sans-serif\"),\n",
    ")\n",
    "fig.layout.title.font = dict(\n",
    "    size=16,\n",
    "    family=\"Arial, sans-serif\",\n",
    ")\n",
    "fig.layout.showlegend = False\n",
    "\n",
    "\n",
    "# Add circles around clusters\n",
    "for cluster in np.unique(labels):\n",
    "    cluster_points = vis_dims_2d[labels == cluster]\n",
    "    center = cluster_points.mean(axis=0)\n",
    "    radius = np.linalg.norm(cluster_points - center, axis=1).max()\n",
    "    # Define circle bounds (Plotly circles use bounding box)\n",
    "    x0, y0 = center - radius\n",
    "    x1, y1 = center + radius\n",
    "    fig.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        x0=x0,\n",
    "        y0=y0,\n",
    "        x1=x1,\n",
    "        y1=y1,\n",
    "        opacity=0.2,\n",
    "        line=dict(\n",
    "            color=\"black\",\n",
    "            width=1,\n",
    "            dash=\"dot\",  # Optional: change to \"solid\", \"dash\", etc. for different styles\n",
    "        ),\n",
    "        fillcolor=\"rgba(0,0,0,0)\",\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ada0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
